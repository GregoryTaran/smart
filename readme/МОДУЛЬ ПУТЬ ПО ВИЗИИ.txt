МОДУЛЬ «ПУТЬ ПО ВИЗИИ» — ВЫЖИМКА
1. Назначение

Модуль «ПУТЬ ПО ВИЗИИ» поддерживает человека в движении к его визии через диалог с системой, фиксируя:

сам объект «визия»;

весь путь-процесс (историю взаимодействий);

статусы визии:

active (активна),

frozen (заморожена / архив),

deleted (удалена с точки зрения интерфейса — soft delete).

UI и конкретные API-роуты не описываем — работаем на уровне логики и данных.

2. Объекты и таблицы
2.1. Пользователь

Пользователь уже авторизован.

У него есть внешний user_id из существующей auth-системы.

В модуле «Путь по визии» мы user_id просто используем, не храним отдельно.

2.2. Визия (visions)

Главный объект.

Таблица public.visions (минимальное ядро):

id — PK (UUID или BIGSERIAL, как решим в проекте)

userid — TEXT (или UUID) — чей это путь

title — TEXT — название визии (черновое авто: «Визия от <дата>»)

status — TEXT — active / frozen / deleted

createdat — TIMESTAMPTZ, по умолчанию now()

updatedat — TIMESTAMPTZ, можно обновлять при изменениях

meta — JSONB, доп. данные (краткое описание, теги и т.п., опционально)

На MVP:

визия создаётся автоматически с черновым названием, редактирование названия — потом.

2.3. Сообщения по визии (vision_messages)

Это наш универсальный шаг пути.
Всё, что происходит в визии (текст, ответы, ссылки на файлы) — это VisionMessage с типом.

Таблица public.vision_messages:

id — PK

visionid — ссылка на visions.id (FK можно добавить позже)

sender — TEXT:

user — сообщение пользователя

assistant — ответ системы

system — служебные записи (опционально)

messagetype — TEXT:

text — обычный текст

audio — аудио (если позже добавим)

file_result — мы что-то сгенерили и отдали файлом

info — системное/служебное сообщение

content — TEXT — основной текст (вопрос / ответ / подпись к файлу)

payload — JSONB — структура с доп. данными (id файла, параметры, и т.д.)

createdat — TIMESTAMPTZ, по умолчанию now()

Примеры:

Пользователь: sender="user", messagetype="text", текст в content.

Ассистент: sender="assistant", messagetype="text", текст в content.

Ассистент с файлом: sender="assistant", messagetype="file_result", content="Вот ваш документ", payload={"fileid": "...", "filename": "..."}.

2.4. Файлы (опционально, если нужно)

Если понадобятся отдельные файлы, можно завести public.files:

id

visionid (опционально)

storagepath / url

mime

size

createdat

meta JSONB

Тогда в vision_messages.payload мы храним только fileid.

2.5. Учёт токенов (tokenscount)

Отдельный универсальный модуль, уже спроектирован.

Таблица public.tokenscount:

id — BIGSERIAL PK

clientid — TEXT (для этого модуля — user_id), но модуль общий и может быть visitor_id и т.п.

clienttype — TEXT ("user", "visitor", "system", …)

provider — TEXT ("openai", и т.д.)

model — TEXT ("gpt-4.1", …)

prompttokens — INTEGER, опционально

completiontokens — INTEGER, опционально

totaltokens — INTEGER, опционально

rawusage — JSONB — сырые данные usage от провайдера

meta — JSONB — доп. данные (например: { "module": "vision", "visionid": "..." })

createdat — TIMESTAMPTZ, по умолчанию now()

Все поля, кроме id, не обязаны быть заполнены.
Модуль tokenscount лежит в backend/tokenscount/ (см. его описание).

3. Жизненный цикл визии (логика без конкретных API)
3.1. Создание визии

Пользователь авторизован, есть user_id.

Нажимает «Создать визию».

Сервер создаёт запись в visions:

userid = user_id

title = "Визия от <текущая дата>"

status = "active"

createdat = now()

Возвращает vision.id.

На этом этапе UI можно не трогать, важна только логика.

3.2. Загрузка визии и её диалога

Когда пользователь открывает визию:

Сервер по visionid:

получает саму визию (visions);

получает список сообщений (vision_messages) отсортированных по createdat.

Возвращает всё это фронту.

Фронт хранит эту историю в памяти (в JS) до перезагрузки.

3.3. Новый шаг (сообщение пользователя + ответ ассистента)

Последовательность:

Пользователь отправляет текст.

Сервер:

создаёт VisionMessage с:

sender="user"

messagetype="text"

content=текст пользователя

собирает историю переписки для GPT:
SELECT * FROM vision_messages WHERE visionid = ... ORDER BY createdat

режет её по правилу: берём последние N сообщений (MVP: MAX_MESSAGES = 50).

сериализует историю в формат диалога для GPT (role=user/assistant, content=...).

вызывает GPT через обёртку, которая логирует токены:

модуль tokenscount,

meta={"module": "vision", "visionid": "<id>"}.

получает ответ модели.

создаёт второй VisionMessage:

sender="assistant"

messagetype="text" (или file_result, если отдали файл)

content=ответ ассистента

Сервер возвращает фронту либо:

только новое сообщение ассистента,

либо (по желанию) пару: сообщение пользователя + ассистента.

Важно:
Истина по истории всегда на сервере в vision_messages.
Фронт просто подгружает/добавляет.

3.4. Статусы визии

active — можно писать новые сообщения.

frozen — визия «в архиве»:

диалог только на чтение,

новые сообщения не принимаются.

deleted — soft delete:

визия скрыта из интерфейса,

данные в БД остаются.

Логика изменения статуса:

отдельный серверный метод «сменить статус визии»;

при deleted — просто ставим статус, физически не удаляем.

4. Агрегация истории для GPT

MVP-правило:

для каждого нового запроса мы берём историю визии из БД,

сортируем по createdat,

берём последние N сообщений (MAX_MESSAGES, например 50),

на основе этого строим prompt.

Позже можно добавить:

векторизацию сообщений;

summary старых частей диалога.

Но на первом этапе — просто последние N сообщений.

5. Интеграция с tokenscount

Любой вызов к GPT из модуля «Путь по визии» должен идти через обёртку tokenscount, чтобы токены считались.

Схема:

Собираем messages для GPT.

Вызываем:

response = await call_model_and_log_tokens(
    db=db,
    client=openai_client,
    clientid=user_id,
    clienttype="user",
    provider="openai",
    model="gpt-4.1",
    messages=messages_for_gpt,
    meta={"module": "vision", "visionid": str(vision_id)},
)


Внутри обёртки:

забираем usage из ответа,

пишем строку в public.tokenscount,

возвращаем response наверх.

Так мы:

не завязываем «Путь по визии» на детали биллинга;

получаем статистику токенов по каждому visionid/user_id через tokenscount.

6. Что оставляем «на потом»

Сейчас НЕ делаем:

сложный UI (только концепт: лента «вопрос–ответ–вопрос–ответ»);

детальные FastAPI-роуты (их можно накидать уже по этой выжимке);

отдельные сущности для событий/стадий пути (vision_events и т.п.);

векторную индексацию.


МОИ ДОПОЛНЕНИЯ
Название: «ПУТЬ ПО ВИЗИИ»
Цель: поддерживать человека в движении к его визии через диалог с системой, фиксируя:
1. сам объект «визия»,
2. весь путь-процесс (историю взаимодействий),
3. статусы визии (активна / заморожена / в архиве / удалена с точки зрения интерфейса).

Состояния/события пути - предлагаю потом добавить, сейчас очень сложно для меня. 

ОБЬЕКТЫ:
1. Пользователь. Пользователь уже авторизован в системе. У пользователя есть уникальный user_id (приходит из существующей auth-системы).
2. Визия (Vision) - Главный объект.
3. Сообщения диалога (VisionMessage). Диалог человека и системы внутри конкретной визии.
мне нужно понять как архитектруно завязать все что будет нами сделанно кромен диалога, например мы сделали пользовтателю выборку, и она в виде вайла, это тоже диалог? или это уже другая сущность?

Пользовательские сценарии:
1. Пользователь (уже залогинен) нажимает кнопку «Создать визию».
2. Система: формирует «черновое» название (например, «Визия от 14.11.2025») и уже потом даёт в списке визий возможность отредактировать или  в другом месте, но потом, сейчас просто создать - создал! не будем усложнять это на начальном этапе, главное что у визии есть id и автоматом текстовое название. так нам будет проще делать суть, а не ебатся с юзер интерфейсом.

3. если говорить о первичном ЮИ это будет просто блочный вывод на странице вопрос - ответ - вопросы - ответ - вопрос - ответ и тд.


АГРЕГИРУЕМ ЗАПРОСЫ
- «Агрегировать запрос в GPT из истории». MVP-логика: Берём все сообщения по визии (SELECT * FROM vision_messages WHERE vision_id = ... ORDER BY created_at). Сериализуем их в формат «диалога» для GPT: роли user / assistant, текстовые части. Отправляем весь диалог в GPT.
Но чтобы не умереть от токенов, сразу строим управляемую константу: Конфиг, например: MAX_MESSAGES = 50

ВЫВОД СООБЩЕНИЙ
- «На начальном MVP каждый раз при первичном запросе визии отправлять клиенту все переписки. Когда пользователь открывает визию:
фронт делает запрос: «дай мне все сообщения по визии» (или последние N). сервер отдаёт список сообщений. фронт сохраняет их у себя в памяти (в JS).  
Когда пользователь отправляет новое сообщение: фронт отправляет только новое сообщение. сервер: сохраняет сообщение пользователя,
вызывает GPT, сохраняет ответ ассистента, возвращает только ответ ассистента (или «пакет» из двух новых сообщений). фронт просто добавляет новые сообщения к уже имеющимся.
сервер отвечает только новым, фронт сам знает, что он уже показал остальное. Если страница перезагрузилась: фронт снова запрашивает историю (GET всех сообщений/последних N), отображает.


