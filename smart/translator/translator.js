// ======== Translator Module (v2.0 â€” global WS + UI options) ========

export async function renderTranslator(mount) {
  mount.innerHTML = `
    <div style="background:#f2f2f2;border-radius:12px;padding:18px;">
      <h2 style="margin:0 0 12px 0;">ğŸ™ï¸ ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸Ğº â€” Ğ¡ÑƒÑ„Ğ»Ñ‘Ñ€</h2>

      <div style="text-align:center;margin-bottom:10px;">
        <label style="font-weight:600;">ğŸ§‘ Ğ“Ğ¾Ğ»Ğ¾Ñ Ğ¾Ğ·Ğ²ÑƒÑ‡ĞºĞ¸:</label>
        <select id="voice-select" style="margin-left:8px;padding:6px 10px;border-radius:6px;">
          <option value="alloy">Alloy (ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹)</option>
          <option value="verse">Verse (Ğ±Ğ°Ñ€Ñ…Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼ÑƒĞ¶ÑĞºĞ¾Ğ¹)</option>
          <option value="echo">Echo (Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹ Ñ‚ĞµĞ¼Ğ±Ñ€)</option>
          <option value="breeze">Breeze (Ğ»Ñ‘Ğ³ĞºĞ¸Ğ¹ Ğ¼ÑƒĞ¶ÑĞºĞ¾Ğ¹)</option>
          <option value="coral">Coral (Ğ¼ÑĞ³ĞºĞ¸Ğ¹ Ğ¼ÑƒĞ¶ÑĞºĞ¾Ğ¹)</option>
          <option value="astra">Astra (Ğ¶ĞµĞ½ÑĞºĞ¸Ğ¹)</option>
        </select>
      </div>

      <div style="text-align:center;margin-bottom:10px;">
        <label style="font-weight:600;">Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸:</label>
        <select id="process-mode" style="margin-left:8px;padding:6px 10px;border-radius:6px;">
          <option value="recognize">ğŸ§ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ</option>
          <option value="translate">ğŸ”¤ ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ñ‡ĞµÑ€ĞµĞ· GPT</option>
          <option value="assistant">ğŸ¤– ĞÑ‚Ğ²ĞµÑ‚ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°</option>
        </select>
      </div>

      <div style="text-align:center;margin-bottom:10px;">
        <label style="font-weight:600;">Ğ¯Ğ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¿Ğ°Ñ€Ğ°:</label>
        <select id="lang-pair" style="margin-left:8px;padding:6px 10px;border-radius:6px;">
          <option value="en-ru">ğŸ‡¬ğŸ‡§ EN â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="es-ru">ğŸ‡ªğŸ‡¸ ES â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="fr-ru">ğŸ‡«ğŸ‡· FR â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="de-ru">ğŸ‡©ğŸ‡ª DE â†” ğŸ‡·ğŸ‡º RU</option>
        </select>
      </div>

      <div style="text-align:center;margin-bottom:10px;">
        <button id="translator-record-btn">Start</button>
        <button id="ctx-stop"
          style="padding:10px 20px;border:none;border-radius:8px;background:#f44336;color:#fff;"
          disabled>Stop</button>
      </div>

      <div id="ctx-log"
        style="white-space:pre-wrap;background:#fff;padding:10px;border-radius:8px;min-height:300px;border:1px solid #ccc;font-size:14px;overflow:auto;">
      </div>
    </div>
  `;

  const logEl = mount.querySelector("#ctx-log");
  const btnStart = mount.querySelector("#translator-record-btn");
  const btnStop  = mount.querySelector("#ctx-stop");
  const procSel  = mount.querySelector("#process-mode");
  const langSel  = mount.querySelector("#lang-pair");
  const voiceSel = mount.querySelector("#voice-select");

  function log(msg) {
    const div = document.createElement("div");
    div.innerHTML = msg.replace(/(https?:\/\/[^\s]+)/g, '<a href="$1" target="_blank">$1</a>');
    logEl.appendChild(div);
    logEl.scrollTop = logEl.scrollHeight;
  }

  let ws, audioCtx, worklet, stream;
  let buffer = [], sessionId = null, sampleRate = 48000, lastSend = 0;

  // === Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ WebSocket ===
  const WS_URL = location.origin.replace(/^http/, "wss");

  btnStart.onclick = async () => {
    try {
      const processMode = procSel.value;
      const langPair = langSel.value;
      const voice = voiceSel.value;
      const mode = "agc";

      ws = new WebSocket(WS_URL);
      ws.binaryType = "arraybuffer";

      ws.onmessage = (e) => {
        const msg = String(e.data);
        if (msg.startsWith("SESSION:")) {
          sessionId = msg.split(":")[1];
          log("ğŸ“© " + msg);
        } else log(msg);
      };

      ws.onopen = () => {
        ws.send(JSON.stringify({
          type: "register",
          module: "translator",
          sampleRate,
        }));
        ws.send(JSON.stringify({
          type: "meta",
          sampleRate,
          mode,
          processMode,
          langPair,
          voice,
        }));
        ws.send("ping-init");
        log("âœ… Connected to WebSocket");
      };

      ws.onclose = () => log("âŒ Disconnected");

      audioCtx = new AudioContext({ sampleRate });
      await audioCtx.audioWorklet.addModule("smart/context/recorder-worklet.js");
      const source = audioCtx.createMediaStreamSource(await navigator.mediaDevices.getUserMedia({ audio: true }));
      worklet = new AudioWorkletNode(audioCtx, "recorder-processor");
      source.connect(worklet);

      worklet.port.onmessage = (e) => {
        const chunk = e.data;
        buffer.push(chunk);
        const now = performance.now();
        if (now - lastSend >= 1000) {
          sendBlock();
          lastSend = now;
        }
      };

      btnStart.disabled = true;
      btnStop.disabled = false;
      log("ğŸ™ï¸ Recording started (AGC)");
    } catch (e) {
      log("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: " + e.message);
    }
  };

  function concat(chunks) {
    const total = chunks.reduce((a, b) => a + b.length, 0);
    const out = new Float32Array(total);
    let offset = 0;
    for (const part of chunks) {
      out.set(part, offset);
      offset += part.length;
    }
    return out;
  }

  function sendBlock() {
    if (!buffer.length || !ws || ws.readyState !== WebSocket.OPEN) return;
    const full = concat(buffer);
    ws.send(full.buffer);
    buffer = [];
    log(`ğŸ§ Sent ${full.length} samples`);
  }

  btnStop.onclick = async () => {
    try {
      sendBlock();
      if (audioCtx) audioCtx.close();
      if (stream) stream.getTracks().forEach(t => t.stop());
      if (ws && ws.readyState === WebSocket.OPEN) ws.close();
      log("â¹ï¸ Recording stopped");
      btnStart.disabled = false;
      btnStop.disabled = true;

      if (!sessionId) return log("â” ĞĞµÑ‚ sessionId");
      await processSession();
    } catch (e) {
      log("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: " + e.message);
    }
  };

  async function processSession() {
    try {
      const voice = voiceSel.value;
      const processMode = procSel.value;
      const langPair = langSel.value;

      log("ğŸ§© ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ‡Ğ°Ğ½ĞºĞ¸...");
      await fetch(`/translator/merge?session=${sessionId}`);
      log("ğŸ’¾ merged");

      log("ğŸ§  Whisper...");
      const w = await fetch(`/translator/whisper?session=${sessionId}&langPair=${encodeURIComponent(langPair)}`);
      const data = await w.json();
      const text = data.text || "";
      const detectedLang = data.detectedLang || null;
      log("ğŸ§  â†’ " + text);
      log("ğŸŒ Detected language: " + (detectedLang || "none"));

      let finalText = text;
      if (processMode !== "recognize") {
        log("ğŸ¤– GPT...");
        const body = { text, mode: processMode, langPair, detectedLang };
        const g = await fetch("/translator/gpt", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body),
        });
        const gData = await g.json();
        finalText = gData.text;
        log("ğŸ¤– â†’ " + finalText);
      }

      if (finalText) {
        log("ğŸ”Š TTS...");
        const t = await fetch(`/translator/tts?session=${sessionId}&voice=${voice}&text=${encodeURIComponent(finalText)}`);
        const tData = await t.json();
        log(`ğŸ”Š ${tData.url}`);
        const audio = new Audio(tData.url);
        audio.play();
      }
    } catch (e) {
      log("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: " + e.message);
    }
  }
}
