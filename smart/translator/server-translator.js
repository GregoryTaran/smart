import fs from 'fs';
import path from 'path';
import express from 'express';
import { WebSocketServer } from 'ws';
import fetch from 'node-fetch';
import FormData from 'form-data';

// === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
const PORT = 4000; // –ü–æ—Ä—Ç –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const ROOT = path.resolve('.');
const BASE_URL = `http://localhost:${PORT}`;
const APP_DIR = path.join(ROOT, 'translator');

const app = express();
app.use(express.json());
app.use(express.static(APP_DIR)); // –°—Ç–∞—Ç–∏—á–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ translator

// === –°—Ç–∞—Ä—Ç —Å–µ—Ä–≤–µ—Ä–∞ ===
const server = app.listen(PORT, () =>
  console.log(`üöÄ Translator server started on port ${PORT}`)
);

const wss = new WebSocketServer({ server });

// === WebSocket ===
let sessionCounter = 1;
wss.on('connection', (ws) => {
  ws.sampleRate = 44100;
  ws.sessionId = `sess-${sessionCounter++}`;
  ws.chunkCounter = 0;
  ws.send(`SESSION:${ws.sessionId}`);
  console.log(`üéß [translator] New connection: ${ws.sessionId}`);

  ws.on('message', (data) => {
    if (typeof data === 'string') {
      try {
        const meta = JSON.parse(data);
        if (meta.type === 'meta') {
          ws.sampleRate = meta.sampleRate;
          ws.processMode = meta.processMode;
          ws.langPair = meta.langPair;
          ws.voice = meta.voice;
          return ws.send(`üéõ Meta ok: ${ws.sampleRate} Hz`);
        }

        if (meta.type === 'silence') {
          console.log(`üß© [${ws.sessionId}] Silence detected, merging chunks...`);
          mergeChunks(ws.sessionId); // –ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–∫–ª–µ–∏–≤–∞–Ω–∏–µ
        }
      } catch {}
    } else {
      const buf = Buffer.from(data);
      const f32 = new Float32Array(buf.buffer, buf.byteOffset, buf.byteLength / 4);
      const wav = floatToWav(f32, ws.sampleRate);
      const filename = `${ws.sessionId}_chunk_${ws.chunkCounter++}.wav`;
      fs.writeFileSync(filename, wav);
      ws.send(`üíæ Saved ${filename}`);
    }
  });

  ws.on('close', () => console.log(`‚ùå Closed ${ws.sessionId}`));
});

// === –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ ===
function mergeChunks(session) {
  console.log(`üß© [${session}] Starting chunk merge...`);
  const files = fs.readdirSync('.')
    .filter((f) => f.startsWith(`${session}_chunk_`))
    .sort((a, b) => +a.match(/chunk_(\d+)/)[1] - +b.match(/chunk_(\d+)/)[1]);

  if (!files.length) return console.log('No chunks to merge');

  const headerSize = 44;
  const first = fs.readFileSync(files[0]);
  const sr = first.readUInt32LE(24);
  const pcms = files.map((f) => fs.readFileSync(f).subarray(headerSize));
  const totalPCM = Buffer.concat(pcms);
  const merged = makeWav(totalPCM, sr);
  const outFile = `${session}_merged.wav`;
  fs.writeFileSync(outFile, merged);

  console.log(`üß© [${session}] Merged ${files.length} chunks into ${outFile}`);
  // –£–¥–∞–ª–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤
  files.forEach((f) => fs.unlinkSync(f));

  // –î–∞–ª—å—à–µ –≤—ã–∑—ã–≤–∞–µ–º Whisper, GPT –∏ TTS
  processMergedFile(session, outFile);
}

// === –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ —Å–∫–ª–µ–π–∫–∏ ===
async function processMergedFile(session, filePath) {
  try {
    // –ó–∞–ø—É—Å–∫ Whisper
    const whisperResponse = await whisper(filePath);
    const text = whisperResponse.text;

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ GPT –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞
    const gptResponse = await gpt(text, session);

    // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–∑–≤—É—á–∫–∏
    await tts(gptResponse.text, session);

    console.log(`üß† Finished processing ${session}`);
  } catch (e) {
    console.error(`‚ùå Error during file processing: ${e.message}`);
  }
}

// === Whisper ===
async function whisper(filePath) {
  // –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ Whisper API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
  const form = new FormData();
  form.append('file', fs.createReadStream(filePath));
  form.append('model', 'whisper-1');
  form.append('response_format', 'verbose_json');
  form.append('task', 'transcribe');

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: { Authorization: `Bearer ${OPENAI_API_KEY}` },
    body: form,
  });

  const data = await response.json();
  return { text: data.text || '' };
}

// === GPT ===
async function gpt(text, session) {
  // –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ GPT API –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞
  const prompt = `Translate this text: ${text}`;
  const response = await fetch('https://api.openai.com/v1/completions', {
    method: 'POST',
    headers: { Authorization: `Bearer ${OPENAI_API_KEY}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'text-davinci-003',
      prompt: prompt,
      max_tokens: 150,
    }),
  });

  const data = await response.json();
  return { text: data.choices[0].text.trim() };
}

// === TTS ===
async function tts(text, session) {
  // –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ TTS API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–∑–≤—É—á–∫–∏
  const response = await fetch('https://api.openai.com/v1/audio/speech', {
    method: 'POST',
    headers: { Authorization: `Bearer ${OPENAI_API_KEY}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'gpt-4o-mini-tts',
      input: text,
    }),
  });

  const audio = await response.arrayBuffer();
  const file = `${session}_tts.mp3`;
  fs.writeFileSync(file, Buffer.from(audio));
  return { url: `${BASE_URL}/${file}` };
}

// === Helpers ===
function floatToWav(f32, sampleRate) {
  const buffer = Buffer.alloc(44 + f32.length * 2);
  const view = new DataView(buffer.buffer);
  view.setUint32(0, 0x52494646, false);
  view.setUint32(4, 36 + f32.length * 2, true); // –†–∞–∑–º–µ—Ä –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞
  view.setUint32(8, 0x57415645, false); // WAVE
  view.setUint32(12, 0x666d7420, false); // fmt
  view.setUint32(16, 16, true); // –¥–ª–∏–Ω–∞ fmt
  view.setUint16(20, 1, true); // –¢–∏–ø —Ñ–æ—Ä–º–∞—Ç–∞ (1 - PCM)
  view.setUint16(22, 1, true); // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤
  view.setUint32(24, sampleRate, true); // –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
  view.setUint32(28, sampleRate * 2, true); // byte rate
  view.setUint16(32, 2, true); // –±–ª–æ–∫
  view.setUint16(34, 16, true); // —Ä–∞–∑–º–µ—Ä —Å—ç–º–ø–ª–∞
  view.setUint32(36, 0x64617461, false); // data
  view.setUint32(40, f32.length * 2, true); // –î–ª–∏–Ω–∞ –¥–∞–Ω–Ω—ã—Ö

  for (let i = 0; i < f32.length; i++) {
    view.setInt16(44 + i * 2, f32[i] * 32767); // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–ª–æ—Ç –≤ 16-–±–∏—Ç
  }

  return buffer;
}
