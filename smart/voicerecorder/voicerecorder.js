// === Voice Recorder (start-gated, with rich logging) ===
// Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° ĞĞ˜Ğ§Ğ•Ğ“Ğ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµÑ‚, Ğ¿Ğ¾ĞºĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¶Ğ°Ğ» Start.

import SVAudioCore from "./audiocore/sv-audio-core.js";
import WavSegmenter from "./audiocore/wav-segmenter.js";
import MicIndicator from "./mic-indicator/mic-indicator.js";

// ---------- DOM ----------
const statusEl = document.getElementById("status");
const startBtn  = document.getElementById("startBtn");
const pauseBtn  = document.getElementById("pauseBtn");
const stopBtn   = document.getElementById("stopBtn");
const playerEl  = document.getElementById("sv-player");
const listEl    = document.getElementById("record-list");

// Ğ’ĞĞ–ĞĞ: Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—Ğ£Ğ•Ğœ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞ«Ğ™ DOM-Ğ­Ğ›Ğ•ĞœĞ•ĞĞ¢
const micIndicatorEl = document.getElementById("vc-level");

const setStatus = (s) => {
  if (statusEl) statusEl.textContent = s;
  console.log("ğŸ§­ [STATE]", s);
};

// ---------- Globals ----------
let core = null;
let segmenter = null;
let ws = null;
let recordingId = null;
let paused = false;

let indicator = null;

// ---------- WS ----------
async function connectWS(recId) {
  const state = (window.SVID && typeof SVID.getState === "function")
    ? SVID.getState()
    : {};
  const userId = state.user_id || state.visitor_id || "anon";

  const proto = location.protocol === "https:" ? "wss" : "ws";
  const url = `${proto}://${location.host}/ws/voicerecorder`;
  console.log("ğŸŒ [WS] Connecting to:", url);

  ws = new WebSocket(url);

  ws.onopen = () => {
    console.log("âœ… [WS] Connected, sending START");
    ws.send("START " + JSON.stringify({ user_id: userId, rec_id: recId, ext: ".wav" }));
  };

  ws.onmessage = (ev) => {
    console.log("ğŸ“¨ [WS] Message:", ev.data);
    try {
      const d = JSON.parse(ev.data);
      if (d.status === "SAVED") {
        console.log("ğŸ’¾ [WS] Saved file URL:", d.url);

        const li = document.createElement("li");
        li.innerHTML = `<a href="${d.url}" target="_blank">${d.url}</a>`;
        listEl.prepend(li);

        playerEl.src = d.url;
        playerEl.classList.remove("sv-player--disabled");

        setStatus("saved");
      }
    } catch {}
  };

  ws.onerror = (e) => console.error("âŒ [WS] Error:", e);
  ws.onclose = (ev) => console.log("ğŸ›‘ [WS] Closed:", ev.code, ev.reason);
}

async function stopWS() {
  if (ws && ws.readyState === WebSocket.OPEN) {
    console.log("ğŸ§¹ [WS] Sending END");
    ws.send("END");
  }
}

// ---------- Lifecycle ----------
async function start() {
  // Start Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ñ€Ğ°Ğ·, Ğ¿Ğ¾ĞºĞ° Ğ½ĞµÑ‚ core
  if (core) {
    console.log("â¯ [START] core already exists, ignoring click");
    return;
  }

  recordingId = crypto.randomUUID();
  console.log("ğŸ¬ [START] recId =", recordingId);
  setStatus("startingâ€¦");

  // === Audio core ===
  core = new SVAudioCore({
    chunkSize: 2048,
    workletUrl: "voicerecorder/audiocore/recorder.worklet.js",
  });
  await core.init();
  console.log("ğŸ›ï¸ [CORE] AudioContext SR =", core.getContext()?.sampleRate);

  // === Mic indicator ===
  if (!indicator && micIndicatorEl) {
    indicator = new MicIndicator(micIndicatorEl);
  }

  // Ğ’ĞĞ–ĞĞ: Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ½Ñ‹Ğ¹ MediaStream Ğ¸Ğ· SVAudioCore
  const stream = core.getStream ? core.getStream() : null;
  if (indicator && stream) {
    await indicator.connectStream(stream);
    // Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ ÑĞ²Ğ½Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ¼ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñƒ, Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ
    indicator._state = "working";
  }

  // === Segmenter ===
  segmenter = new WavSegmenter({
    sampleRate: core.getContext()?.sampleRate || 48000,
    segmentSeconds: 2,
    normalize: true,
    emitBlobPerSegment: true
  });

  segmenter.onSegment = (seg) => {
    if (!seg?.blob) return;
    if (!ws || ws.readyState !== WebSocket.OPEN) {
      console.warn("ğŸ“¦ [SEG] drop WS not ready", seg.seq);
      return;
    }
    console.log(
      "ğŸ“¦ [SEG] send chunk seq",
      seg.seq,
      "dur",
      seg.durationSec.toFixed(2),
      "blob",
      seg.blob.size
    );
    ws.send(seg.blob);
  };

  // === Frames â†’ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ĞµÑ€ ===
  core.onAudioFrame = (f32) => {
    if (segmenter) segmenter.pushFrame(f32);
  };

  await connectWS(recordingId);

  paused = false;
  startBtn.setAttribute("disabled", "true");
  pauseBtn.removeAttribute("disabled");
  stopBtn.removeAttribute("disabled");
  setStatus("recording");
}

async function pause() {
  if (!core) return;

  if (!paused) {
    // === ĞŸĞĞ£Ğ—Ğ ===
    core.pauseCapture();
    paused = true;
    pauseBtn.textContent = "Resume";
    setStatus("paused");

    // â›” Ğ¤Ğ Ğ˜Ğ—Ğ˜Ğœ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ (Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ B: Ğ·Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ·ĞºĞ° ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸)
    if (indicator) {
      indicator._state = "pause";
    }

  } else {
    // === Ğ Ğ•Ğ—Ğ®Ğœ ===
    core.resumeCapture();
    paused = false;
    pauseBtn.textContent = "Pause";
    setStatus("recording");

    // â–¶ï¸ Ğ’Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ bars
    if (indicator) {
      indicator._state = "working";
    }
  }
}

async function stop() {
  if (!core) return;

  setStatus("stoppingâ€¦");

  // Ğ°ĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ¾ Ğ³Ğ°ÑĞ¸Ğ¼ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€
  if (indicator) {
    indicator.setInactive();   // ÑĞ±Ñ€Ğ¾Ñ Ğ±ÑƒÑ„ĞµÑ€Ğ° + baseline
    indicator._state = "initial";
  }

  segmenter?.stop();
  await stopWS();

  core.stop();
  core = null;
  segmenter = null;
  ws = null;
  recordingId = null;
  paused = false;

  startBtn.removeAttribute("disabled");
  pauseBtn.setAttribute("disabled", "true");
  stopBtn.setAttribute("disabled", "true");
  pauseBtn.textContent = "Pause";

  setStatus("idle");
  console.log("ğŸ [STOP] done");
}

// Bind UI
document.addEventListener("DOMContentLoaded", () => {
  startBtn.addEventListener("click", start);
  pauseBtn.addEventListener("click", pause);
  stopBtn.addEventListener("click", stop);
  console.log("ğŸ§· [BIND] ready");
});
