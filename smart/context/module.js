// ======== Context Module (v1.4 â€” process chain with GPT modes) ========

export async function render(mount) {
  mount.innerHTML = `
    <div style="background:#f2f2f2; border-radius:12px; padding:18px;">
      <h2 style="margin:0 0 12px 0;">ğŸ§ Context v1 â€” Audio â†’ Server â†’ Whisper â†’ GPT â†’ TTS</h2>

      <div style="text-align:center; margin-bottom:10px;">
        <label style="font-weight:600;">Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ°:</label>
        <select id="capture-mode" style="margin-left:8px; padding:6px 10px; border-radius:6px;">
          <option value="raw">ğŸ§ RAW â€” Ğ±ĞµĞ· Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸</option>
          <option value="agc">ğŸ§  AGC â€” Ğ°Ğ²Ñ‚Ğ¾ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ</option>
          <option value="gain">ğŸ“¢ GAIN â€” Ñ€ÑƒÑ‡Ğ½Ğ¾Ğµ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ</option>
        </select>
      </div>

      <div style="text-align:center; margin-bottom:10px;">
        <label style="font-weight:600;">Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸:</label>
        <select id="process-mode" style="margin-left:8px; padding:6px 10px; border-radius:6px;">
          <option value="recognize">ğŸ§ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ</option>
          <option value="translate">ğŸ”¤ ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ñ‡ĞµÑ€ĞµĞ· GPT</option>
          <option value="assistant">ğŸ¤– ĞÑ‚Ğ²ĞµÑ‚ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°</option>
        </select>
      </div>

      <div style="text-align:center; margin-bottom:10px;">
        <label style="font-weight:600;">Ğ¯Ğ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¿Ğ°Ñ€Ğ°:</label>
        <select id="lang-pair" style="margin-left:8px; padding:6px 10px; border-radius:6px;">
          <option value="en-ru">ğŸ‡¬ğŸ‡§ EN â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="es-ru">ğŸ‡ªğŸ‡¸ ES â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="fr-ru">ğŸ‡«ğŸ‡· FR â†” ğŸ‡·ğŸ‡º RU</option>
          <option value="de-ru">ğŸ‡©ğŸ‡ª DE â†” ğŸ‡·ğŸ‡º RU</option>
        </select>
      </div>

      <div class="controls" style="text-align:center; margin-bottom:10px;">
        <button id="ctx-start" style="padding:10px 20px;border:none;border-radius:8px;background:#4caf50;color:#fff;">Start</button>
        <button id="ctx-stop"  style="padding:10px 20px;border:none;border-radius:8px;background:#f44336;color:#fff;" disabled>Stop</button>
      </div>

      <div id="ctx-log" style="white-space:pre-wrap;background:#fff;padding:10px;border-radius:8px;min-height:300px;border:1px solid #ccc;font-size:14px;overflow:auto;"></div>
    </div>
  `;

  const logEl = mount.querySelector("#ctx-log");
  const btnStart = mount.querySelector("#ctx-start");
  const btnStop  = mount.querySelector("#ctx-stop");
  const modeSel  = mount.querySelector("#capture-mode");
  const procSel  = mount.querySelector("#process-mode");
  const langSel  = mount.querySelector("#lang-pair");

  const WS_URL = `${location.origin.replace(/^http/, "ws")}/ws`;
  let ws, audioCtx, worklet, stream;
  let buffer = [], total = 0, lastSend = 0, sampleRate = 44100, sessionId = null;

  function log(msg) {
    const linked = msg.replace(/(https?:\/\/[^\s]+)/g, (url) => `<a href="${url}" target="_blank">${url}</a>`);
    const line = document.createElement("div");
    line.innerHTML = linked;
    logEl.appendChild(line);
    logEl.scrollTop = logEl.scrollHeight;
    console.log(msg);
  }
  function logError(err) {
    console.error(err);
    log("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: " + (err?.message || String(err)));
  }

  btnStart.onclick = async () => {
    try {
      const mode = modeSel.value;
      const processMode = procSel.value;
      const langPair = langSel.value;

      ws = new WebSocket(WS_URL);
      ws.binaryType = "arraybuffer";
      ws.onmessage = (e) => {
        const msg = String(e.data);
        if (msg.startsWith("SESSION:")) {
          sessionId = msg.split(":")[1];
          log("ğŸ“© SESSION:" + sessionId);
        } else log("ğŸ“© " + msg);
      };
      ws.onclose = () => log("âŒ Disconnected");

      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      sampleRate = audioCtx.sampleRate;
      log("ğŸ› Detected SampleRate: " + sampleRate + " Hz");
      await audioCtx.audioWorklet.addModule("context/recorder-worklet.js");

      ws.onopen = () => {
        log("âœ… Connected to WebSocket server");
        ws.send(JSON.stringify({ type: "meta", sampleRate, mode, processMode, langPair }));
      };

      const constraints = (mode === "agc")
        ? { audio: { autoGainControl: true, noiseSuppression: true, echoCancellation: true } }
        : { audio: { autoGainControl: false, noiseSuppression: false, echoCancellation: false } };

      stream = await navigator.mediaDevices.getUserMedia(constraints);
      const source = audioCtx.createMediaStreamSource(stream);
      worklet = new AudioWorkletNode(audioCtx, "recorder-processor");
      source.connect(worklet);

      const INTERVAL = 2000;
      lastSend = performance.now();

      worklet.port.onmessage = (e) => {
        const chunk = e.data;
        buffer.push(chunk);
        total += chunk.length;
        const now = performance.now();
        if (now - lastSend >= INTERVAL) {
          sendBlock();
          lastSend = now;
        }
      };

      log("ğŸ™ï¸ Recording started");
      btnStart.disabled = true;
      btnStop.disabled = false;
    } catch (err) {
      logError(err);
    }
  };

  function concat(chunks) {
    const totalLen = chunks.reduce((a, b) => a + b.length, 0);
    const res = new Float32Array(totalLen);
    let offset = 0;
    for (const part of chunks) {
      res.set(part, offset);
      offset += part.length;
    }
    return res;
  }

  function sendBlock(pad = false) {
    if (!buffer.length) return;
    let full = concat(buffer);
    if (pad) {
      const target = Math.round(sampleRate * 2);
      if (full.length < target) {
        const padded = new Float32Array(target);
        padded.set(full);
        full = padded;
        log("ğŸ«§ Padded last block");
      }
    }
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send(full.buffer);
      log("ğŸ§ Sent " + full.byteLength + " bytes @ " + sampleRate + " Hz");
    }
    buffer = [];
    total = 0;
  }

  btnStop.onclick = () => {
    try {
      sendBlock(true);
      if (audioCtx) audioCtx.close();
      if (stream) stream.getTracks().forEach(t => t.stop());
      if (ws && ws.readyState === WebSocket.OPEN) ws.close();
      log("â¹ï¸ Stopped");
      btnStart.disabled = false;
      btnStop.disabled = true;

      // === POST-PROCESS CHAIN ===
      setTimeout(async () => {
        try {
          if (!sessionId) return log("â” ĞĞµÑ‚ sessionId");

          log("ğŸ§© ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ‡Ğ°Ğ½ĞºĞ¸...");
          const merge = await fetch(`/merge?session=${sessionId}`);
          if (!merge.ok) throw new Error(await merge.text());
          const mergedUrl = location.origin + "/" + sessionId + "_merged.wav";
          log(`ğŸ’¾ Ğ¤Ğ°Ğ¹Ğ» Ğ³Ğ¾Ñ‚Ğ¾Ğ²: ${mergedUrl}`);

          log("ğŸ§  Whisper â†’ Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‘Ğ¼...");
          const w = await fetch(`/whisper?session=${sessionId}`);
          const data = await w.json();
          if (!w.ok) throw new Error(data?.error || "Whisper error");
          const text = data.text || "";
          log("ğŸ§  Whisper â†’ " + text);

          let finalText = text;
          const processMode = procSel.value;
          const langPair = langSel.value;

          if (processMode === "translate" || processMode === "assistant") {
            log("ğŸ¤– ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² GPT...");
            const body = {
              text,
              mode: processMode,
              langPair
            };
            const gptRes = await fetch("/gpt", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify(body)
            });
            const gptData = await gptRes.json();
            if (!gptRes.ok) throw new Error(gptData?.error || "GPT error");
            finalText = gptData.text;
            log("ğŸ¤– GPT â†’ " + finalText);
          }

          if (finalText) {
            log("ğŸ”Š TTS â†’ ĞĞ·Ğ²ÑƒÑ‡ĞºĞ°...");
            const tts = await fetch(`/tts?session=${sessionId}&text=${encodeURIComponent(finalText)}`);
            const ttsData = await tts.json();
            if (!tts.ok) throw new Error(ttsData?.error || "TTS error");
            log(`ğŸ”Š Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾: ${ttsData.url}`);
          }
        } catch (e) {
          logError(e);
        }
      }, 800);
    } catch (e) {
      logError(e);
    }
  };
}
